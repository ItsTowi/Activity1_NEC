{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c392b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNet:\n",
    "    def __init__(self, layers, epochs, lr, momentum, function, perc_validation):\n",
    "        self.L = len(layers)    #Number of layers\n",
    "        self.n = layers.copy()  #An array with the number of units in each layer\n",
    "\n",
    "        self.h = []             #An array of arrays for the fields (h)\n",
    "        for lay in range(self.L):\n",
    "            self.h.append(np.zeros(layers[lay]))\n",
    "        self.xi = []            #An array of arrays for the activations(Xi)\n",
    "        for lay in range(self.L):\n",
    "            self.xi.append(np.zeros(layers[lay]))\n",
    "\n",
    "        self.w = []             #An array of matrices for the weights\n",
    "        self.w.append(np.zeros((1, 1)))\n",
    "        for lay in range(1, self.L):\n",
    "            self.w.append(np.zeros((layers[lay], layers[lay - 1])))\n",
    "\n",
    "        self.theta = []         #An array of arrays for thresholds\n",
    "        for lay in range(self.L):\n",
    "            self.theta.append(np.zeros(layers[lay]))\n",
    "        \n",
    "        self.delta = []         #An array of arrays for the propagation errors\n",
    "        self.d_w = []           #An array of matrices for the changes on weights\n",
    "        self.d_theta = []       #An array of arrays for the changes on thresholds\n",
    "        self.d_w_prev = []      #An array of matrices for the previoius changes of the \n",
    "                                #weights used for the momentum term\n",
    "        self.d_theta_prev = []  #An array of arrays for the previous changes of the \n",
    "                                #thresholds used for the momentum term\n",
    "        self.fact = function      #The name of the activation function that will be \n",
    "                                #used (sigmoid, relu, linear, tanh)\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.perc_validation = perc_validation\n",
    "                                \n",
    "        \n",
    "    \n",
    "    def initialize_w_theta(self):\n",
    "        for L in range(1, self.L):\n",
    "            self.w[L] = np.random.randn(self.n[L], self.n[L-1]) * 0.5\n",
    "        for L in range(1, self.L):\n",
    "            self.theta[L] = np.random.randn(self.n[L]) * 0.5\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        self.xi[0] = X\n",
    "        for L in range(1, self.L):\n",
    "            num_neurons = self.n[L]\n",
    "            for i in range (0, num_neurons):\n",
    "                self.xi[L][i] = self.activation_function(i, L)\n",
    "                \n",
    "        return self.xi[L]\n",
    "    \n",
    "    def activation_function(self, i, L):\n",
    "        self.h[L][i] = 0\n",
    "        for j in range(0, self.n[L-1]):\n",
    "            self.h[L][i] += self.w[L][i, j] * self.xi[L-1][j]\n",
    "            \n",
    "        self.h[L][i] -= self.theta[L][i]\n",
    "            \n",
    "        return (1 / (1 + np.exp(-self.h[L][i])))\n",
    "    \n",
    "    def error_back_propagation(self, out_x, y):\n",
    "        \n",
    "        L = self.L\n",
    "        self.delta[L] = (out_x - y) * self.xi[L] * (1 - self.xi[L])\n",
    "        \n",
    "        for L in range(self.L - 1, 0, -1):\n",
    "            for j in range(0, self.n[L]):\n",
    "                sum_delta = 0\n",
    "                for i in range(self.n[L+1]):\n",
    "                    sum_delta += self.delta[L+1][i] * self.w[L+1][i,j]\n",
    "                self.delta[L][j] = self.xi[L][j] * (1 - self.xi[L][j]) * sum_delta\n",
    "        \n",
    "        \n",
    "                   \n",
    "    def fit(self,X,y):\n",
    "        self.initialize_w_theta()\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for pat in range(X.shape[0]):\n",
    "                #Choose a random pattern (xu zu) of training set\n",
    "                output = self.feed_forward(X[pat])\n",
    "                print(output)    \n",
    "                #Back-propagate the error for this pattern\n",
    "                #Update the weights and threseholds\n",
    "            #Feed-forward all training patterns\n",
    "            #Feed-forward all validation paterns\n",
    "        #Feed-forward all test partterns\n",
    "        #Descale and evaluate\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.feed_forward(x) for x in X])\n",
    "    def loss_epochs():\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f5ded2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed-forward outputs:\n",
      "Input 0: [0.1 0.2 0.3 0.4] -> Output: [0.71914482]\n",
      "Input 1: [0.5 0.4 0.3 0.2] -> Output: [0.71683582]\n",
      "Input 2: [0.9 0.8 0.7 0.6] -> Output: [0.7111944]\n",
      "Activaciones capa 0: [0.9 0.8 0.7 0.6]\n",
      "Activaciones capa 1: [0.16410673 0.75965658 0.31523687 0.55111987 0.33253429 0.35317588\n",
      " 0.2784416  0.60745961 0.60892749]\n",
      "Activaciones capa 2: [0.37138557 0.42852333 0.58074    0.49252724 0.75620211]\n",
      "Activaciones capa 3: [0.7111944]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([\n",
    "    [0.1, 0.2, 0.3, 0.4],\n",
    "    [0.5, 0.4, 0.3, 0.2],\n",
    "    [0.9, 0.8, 0.7, 0.6]\n",
    "])      \n",
    "\n",
    "layers = [4, 9, 5, 1]\n",
    "nn = NeuralNet(layers, 10, 0, 0, \"sigmoid\", 0)\n",
    "\n",
    "\"\"\"\n",
    "print(\"L = \", nn.L, end=\"\\n\")\n",
    "print(\"n = \", nn.n, end=\"\\n\")\n",
    "\n",
    "print(\"xi = \", nn.xi, end=\"\\n\")\n",
    "print(\"xi[0] = \", nn.xi[0], end=\"\\n\")\n",
    "print(\"xi[1] = \", nn.xi[0], end=\"\\n\")\n",
    "\n",
    "print(\"wh = \", nn.w, end=\"\\n\")\n",
    "print(\"wh[1] = \", nn.w[1], end=\"\\n\")\n",
    "\"\"\"\n",
    "\n",
    "# Inicializamos pesos y bias\n",
    "nn.initialize_w_theta()\n",
    "\n",
    "# --- Probamos feed-forward para cada patrÃ³n ---\n",
    "print(\"Feed-forward outputs:\")\n",
    "for idx, x in enumerate(X_train):\n",
    "    output = nn.feed_forward(x)\n",
    "    print(f\"Input {idx}: {x} -> Output: {output}\")\n",
    "   \n",
    "print(\"Activaciones capa 0:\", nn.xi[0]) \n",
    "print(\"Activaciones capa 1:\", nn.xi[1])\n",
    "print(\"Activaciones capa 2:\", nn.xi[2])\n",
    "print(\"Activaciones capa 3:\", nn.xi[3])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
